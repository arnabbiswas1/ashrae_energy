{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import feather\n",
    "import gc\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATED_DATA_DIR = '/home/jupyter/kaggle/energy/data/read_only_feather/v1'\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def read_data(data_dir):\n",
    "    print('Reading Data...')\n",
    "    train_df = feather.read_dataframe(f'{data_dir}/train_merged.feather')\n",
    "    test_df = feather.read_dataframe(f'{data_dir}/test_merged.feather')\n",
    "    print(f'Shape of train_df : {train_df.shape}')\n",
    "    print(f'Shape of test_df : {test_df.shape}')\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def create_date_features(df, feature_name):\n",
    "    '''\n",
    "    Create new features related to dates\n",
    "    \n",
    "    df : The complete dataframe\n",
    "    feature_name : Name of the feature of date type which needs to be decomposed.\n",
    "    '''\n",
    "    print('Creating date related fetaures...')\n",
    "    df.loc[:, 'year'] = df.loc[:, feature_name].dt.year.astype('uint16')\n",
    "    df.loc[:, 'month'] = df.loc[:, feature_name].dt.month.astype('uint8')\n",
    "    df.loc[:, 'quarter'] = df.loc[:, feature_name].dt.quarter.astype('uint8')\n",
    "    df.loc[:, 'weekofyear'] = df.loc[:, feature_name].dt.weekofyear.astype('uint8')\n",
    "    \n",
    "    df.loc[:, 'day'] = df.loc[:, feature_name].dt.day.astype('uint16')\n",
    "    df.loc[:, 'dayofweek'] = df.loc[:, feature_name].dt.dayofweek.astype('uint8')\n",
    "    df.loc[:, 'dayofyear'] = df.loc[:, feature_name].dt.dayofyear.astype('uint16')\n",
    "    df.loc[:, 'is_month_start'] = df.loc[:, feature_name].dt.is_month_start\n",
    "    df.loc[:, 'is_month_end'] = df.loc[:, feature_name].dt.is_month_end\n",
    "    df.loc[:, 'is_quarter_start']= df.loc[:, feature_name].dt.is_quarter_start\n",
    "    df.loc[:, 'is_quarter_end'] = df.loc[:, feature_name].dt.is_quarter_end\n",
    "    df.loc[:, 'is_year_start'] = df.loc[:, feature_name].dt.is_year_start\n",
    "    df.loc[:, 'is_year_end'] = df.loc[:, feature_name].dt.is_year_end\n",
    "    \n",
    "    df.loc[:, 'hour'] = df.loc[:, feature_name].dt.hour.astype('uint8')    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_data_splits_by_fraction(dataframe, valid_fraction=0.1):\n",
    "    \"\"\"\n",
    "    Creating holdout set from the train data based on fraction\n",
    "    \"\"\"\n",
    "    print(f'Splitting the data into train and holdout with validation fraction {valid_fraction}...')\n",
    "    valid_size = int(len(dataframe) * valid_fraction)\n",
    "    train = dataframe[:valid_size]\n",
    "    validation = dataframe[valid_size:]\n",
    "    print(f'Shape of the training data {train.shape} ')\n",
    "    print(f'Shape of the validation data {validation.shape}')\n",
    "    return train, validation\n",
    "\n",
    "\n",
    "def get_data_splits_by_month(dataframe, train_months, validation_months):\n",
    "    \"\"\"\n",
    "    Creating holdout set from the train data based on months\n",
    "    \"\"\"\n",
    "    print(f'Splitting the data into train and holdout based on months...')\n",
    "    print(f'Training months {train_months}')\n",
    "    print(f'Validation months {validation_months}')\n",
    "    training = dataframe[dataframe.month.isin(train_months)]\n",
    "    validation = dataframe[dataframe.month.isin(validation_months)]\n",
    "    print(f'Shape of the training data {training.shape} ')\n",
    "    print(f'Shape of the validation data {validation.shape}')\n",
    "    return training, validation\n",
    "\n",
    "\n",
    "def train_model(training, validation,predictors, taget,  params, test_X=None):\n",
    "    \n",
    "    train_X = training[predictors]\n",
    "    train_Y = np.log1p(training[target])\n",
    "    validation_X = validation[predictors]\n",
    "    validation_Y = np.log1p(validation[target])\n",
    "\n",
    "    print(f'Shape of train_X : {train_X.shape}')\n",
    "    print(f'Shape of train_Y : {train_Y.shape}')\n",
    "    print(f'Shape of validation_X : {validation_X.shape}')\n",
    "    print(f'Shape of validation_Y : {validation_Y.shape}')\n",
    "    \n",
    "    dtrain = lgb.Dataset(train_X, label=train_Y)\n",
    "    dvalid = lgb.Dataset(validation_X, validation_Y)\n",
    "    \n",
    "    print(\"Training model!\")\n",
    "    bst = lgb.train(params, dtrain, valid_sets=[dvalid], verbose_eval=100)\n",
    "    \n",
    "    valid_prediction = bst.predict(validation_X)\n",
    "    valid_score = np.sqrt(metrics.mean_squared_error(validation_Y, valid_prediction))\n",
    "    print(f'Validation Score {valid_score}')\n",
    "    \n",
    "    if test_X is not None:\n",
    "        print('Do Nothing')\n",
    "    else:\n",
    "        return bst, valid_score\n",
    "\n",
    "\n",
    "def make_prediction(df_train_X, df_train_Y, df_test_X, params, n_splits=5):\n",
    "    yoof = np.zeros(len(df_train_X))\n",
    "    yhat = np.zeros(len(df_test_X))\n",
    "    cv_scores = []\n",
    "    result_dict = {}\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, random_state=SEED, shuffle=False)\n",
    "\n",
    "    fold = 0\n",
    "    for in_index, oof_index in kf.split(df_train_X, df_train_Y):\n",
    "        fold += 1\n",
    "        print(f'fold {fold} of {n_splits}')\n",
    "        X_in, X_oof = df_train_X.iloc[in_index].values, df_train_X.iloc[oof_index].values\n",
    "        y_in, y_oof = df_train_Y.iloc[in_index].values, df_train_Y.iloc[oof_index].values\n",
    "        \n",
    "        lgb_train = lgb.Dataset(X_in, y_in)\n",
    "        lgb_eval = lgb.Dataset(X_oof, y_oof, reference=lgb_train)\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            lgb_train,\n",
    "            valid_sets = [lgb_train, lgb_eval],\n",
    "            verbose_eval = 50,\n",
    "        )   \n",
    "        \n",
    "        del lgb_train, lgb_eval, in_index, X_in, y_in \n",
    "        gc.collect()\n",
    "        \n",
    "        print('Training completed')\n",
    "        yoof[oof_index] = model.predict(X_oof)\n",
    "        print('OOF Prediction completed.')\n",
    "        prediction = model.predict(df_test_X.values)\n",
    "        print('Shape of prediction', prediction.shape)\n",
    "        yhat += np.expm1(prediction)\n",
    "        print('Prediction completed')\n",
    "        cv_oof_score = np.sqrt(metrics.mean_squared_error(y_oof, yoof[oof_index]))\n",
    "        print(f'CV OOF Score for fold {fold} is {cv_oof_score}')\n",
    "        cv_scores.append(cv_oof_score)\n",
    "        \n",
    "        del oof_index, X_oof, y_oof\n",
    "        gc.collect()\n",
    "\n",
    "    yhat /= n_splits\n",
    "\n",
    "    oof_score = round(np.sqrt(metrics.mean_squared_error(df_train_Y, yoof)), 5)\n",
    "    avg_cv_scores = round(sum(cv_scores)/len(cv_scores), 5)\n",
    "    std_cv_scores = round(np.array(cv_scores).std(), 5)\n",
    "\n",
    "    print(f'Combined OOF score : {oof_score}')\n",
    "    print(f'Average of {fold} folds OOF score {avg_cv_scores}')\n",
    "    print(f'std of {fold} folds OOF score {std_cv_scores}')\n",
    "    \n",
    "    result_dict['yoof'] = yoof\n",
    "    result_dict['prediction'] = yhat\n",
    "    result_dict['oof_score'] = oof_score\n",
    "    result_dict['cv_scores'] = cv_scores\n",
    "    result_dict['avg_cv_scores'] = avg_cv_scores\n",
    "    result_dict['std_cv_scores'] = std_cv_scores\n",
    "    \n",
    "    return result_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "LOCAl_TEST = True\n",
    "set_seed(SEED)\n",
    "target = 'meter_reading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/pyarrow/pandas_compat.py:752: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_df : (20216100, 16)\n",
      "Shape of test_df : (41697600, 16)\n",
      "Shape of train : (20216100, 16)\n",
      "Shape of test : (41697600, 16)\n",
      "Sorting values based on timestamp, site_id, building_id...\n",
      "CPU times: user 55.4 s, sys: 21.8 s, total: 1min 17s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df, test_df = read_data(CREATED_DATA_DIR)\n",
    "\n",
    "train_ordered_column_names = ['site_id', 'building_id', 'timestamp', 'meter',\n",
    "       'primary_use', 'square_feet', 'year_built', 'floor_count',\n",
    "       'air_temperature', 'cloud_coverage', 'dew_temperature',\n",
    "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
    "       'wind_speed', 'meter_reading']\n",
    "\n",
    "#Include row_id. All columns except meter_reading\n",
    "test_ordered_column_names = ['row_id', 'site_id', 'building_id', 'timestamp', 'meter',\n",
    "       'primary_use', 'square_feet', 'year_built', 'floor_count',\n",
    "       'air_temperature', 'cloud_coverage', 'dew_temperature',\n",
    "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
    "       'wind_speed']\n",
    "\n",
    "# Order the column names in convenient order\n",
    "train_df = train_df[train_ordered_column_names]\n",
    "test_df = test_df[test_ordered_column_names]\n",
    "print(f'Shape of train : {train_df.shape}')\n",
    "print(f'Shape of test : {test_df.shape}')\n",
    "\n",
    "# Sort train and test based on time\n",
    "print('Sorting values based on timestamp, site_id, building_id...')\n",
    "train_df.sort_values(['timestamp', 'site_id', 'building_id'], inplace=True)\n",
    "test_df.sort_values(['timestamp', 'site_id', 'building_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create date features\n",
    "2. LabelEncoding for primary_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding...\n",
      "Label Encoding completed...\n",
      "Creating date related fetaures...\n",
      "Creating date related fetaures...\n",
      "CPU times: user 4min 37s, sys: 1min 45s, total: 6min 23s\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Do label encoding for the String type of feature\n",
    "feature_name = 'primary_use'\n",
    "print('Label Encoding...')\n",
    "lb = LabelEncoder()\n",
    "lb.fit(list(train_df[feature_name].values) + list(test_df[feature_name].values))\n",
    "train_df[feature_name] = lb.transform(list(train_df[feature_name].values))\n",
    "test_df[feature_name] = lb.transform(list(test_df[feature_name].values))\n",
    "print('Label Encoding completed...')\n",
    "\n",
    "# Add date related features.\n",
    "train_df = create_date_features(train_df, 'timestamp')\n",
    "test_df = create_date_features(test_df, 'timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove time stamp and meter reading\n",
    "predictors = ['site_id', 'building_id', 'meter', 'primary_use',\n",
    "       'square_feet', 'year_built', 'floor_count', 'air_temperature',\n",
    "       'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr',\n",
    "       'sea_level_pressure', 'wind_direction', 'wind_speed',\n",
    "       'year', 'month', 'quarter', 'weekofyear', 'day', 'dayofweek',\n",
    "       'dayofyear', 'is_month_start', 'is_month_end', 'is_quarter_start',\n",
    "       'is_quarter_end', 'is_year_start', 'is_year_end', 'hour']\n",
    "\n",
    "#Copied the params from Konstatien's kernel\n",
    "lgb_params = {\n",
    "                'objective':'regression',\n",
    "                'boosting_type':'gbdt',\n",
    "                'metric':'rmse',\n",
    "                'n_jobs':-1,\n",
    "                'learning_rate':0.05,\n",
    "                'num_leaves': 2**8,\n",
    "                'max_depth':-1,\n",
    "                'tree_learner':'serial',\n",
    "                'colsample_bytree': 0.9,\n",
    "                'subsample_freq':1,\n",
    "                'subsample':0.5,\n",
    "                'n_estimators':2000,\n",
    "                'max_bin':255,\n",
    "                'verbose':-1,\n",
    "                'seed': SEED,\n",
    "                'early_stopping_rounds':100, \n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation 1 : 50% Training : 50% Holdout split without shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the data into train and holdout with validation fraction 0.5...\n",
      "Shape of the training data (10108050, 30) \n",
      "Shape of the validation data (10108050, 30)\n"
     ]
    }
   ],
   "source": [
    "training, validation = get_data_splits_by_fraction(train_df, valid_fraction=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X : (10108050, 28)\n",
      "Shape of train_Y : (10108050,)\n",
      "Shape of validation_X : (10108050, 28)\n",
      "Shape of validation_Y : (10108050,)\n",
      "Training model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.59343\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's rmse: 1.56869\n",
      "Validation Score 1.5686904753390896\n"
     ]
    }
   ],
   "source": [
    "bst, valid_score = train_model(training, validation, predictors, target, params=lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del training, validation, bst, valid_score\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation 2 : Train on first 4 months, skip next 4 months, Test on last 4 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the data into train and holdout based on months...\n",
      "Training months [1, 2, 3, 4]\n",
      "Validation months [9, 10, 11, 12]\n",
      "Shape of the training data (6465489, 30) \n",
      "Shape of the validation data (6857643, 30)\n"
     ]
    }
   ],
   "source": [
    "# Training on 1st four months\n",
    "train_months = [1, 2, 3, 4]\n",
    "# Holdout on last four months\n",
    "validation_months = [9, 10, 11, 12]\n",
    "\n",
    "training, validation = get_data_splits_by_month(train_df, train_months=train_months, validation_months=validation_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X : (6465489, 28)\n",
      "Shape of train_Y : (6465489,)\n",
      "Shape of validation_X : (6857643, 28)\n",
      "Shape of validation_Y : (6857643,)\n",
      "Training model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.70705\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's rmse: 1.6958\n",
      "Validation Score 1.695804545268327\n"
     ]
    }
   ],
   "source": [
    "bst, valid_score = train_model(training, validation, predictors, target, params=lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_months, validation_months, training, validation, bst, valid_score\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train_X (20216100, 28)\n",
      "Size of train_Y (20216100,)\n",
      "Size of test_X (41697600, 28)\n",
      "Size of test_row_id (41697600,)\n"
     ]
    }
   ],
   "source": [
    "train_X = train_df[predictors]\n",
    "train_Y = np.log1p(train_df[target])\n",
    "test_X = test_df[predictors]\n",
    "test_row_id = test_df['row_id']\n",
    "\n",
    "print(f'Size of train_X {train_X.shape}')\n",
    "print(f'Size of train_Y {train_Y.shape}')\n",
    "print(f'Size of test_X {test_X.shape}')\n",
    "print(f'Size of test_row_id {test_row_id.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_df, test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's rmse: 1.1718\tvalid_1's rmse: 1.30494\n",
      "[100]\ttraining's rmse: 0.984889\tvalid_1's rmse: 1.13393\n",
      "[150]\ttraining's rmse: 0.898141\tvalid_1's rmse: 1.08127\n",
      "[200]\ttraining's rmse: 0.84526\tvalid_1's rmse: 1.04139\n",
      "[250]\ttraining's rmse: 0.806716\tvalid_1's rmse: 1.01566\n",
      "[300]\ttraining's rmse: 0.779948\tvalid_1's rmse: 0.997234\n",
      "[350]\ttraining's rmse: 0.755243\tvalid_1's rmse: 0.983163\n",
      "[400]\ttraining's rmse: 0.736672\tvalid_1's rmse: 0.975835\n",
      "[450]\ttraining's rmse: 0.721366\tvalid_1's rmse: 0.966542\n",
      "[500]\ttraining's rmse: 0.704898\tvalid_1's rmse: 0.959113\n",
      "[550]\ttraining's rmse: 0.691294\tvalid_1's rmse: 0.955199\n",
      "[600]\ttraining's rmse: 0.679722\tvalid_1's rmse: 0.950524\n",
      "[650]\ttraining's rmse: 0.67059\tvalid_1's rmse: 0.947532\n",
      "[700]\ttraining's rmse: 0.660253\tvalid_1's rmse: 0.944575\n",
      "[750]\ttraining's rmse: 0.651208\tvalid_1's rmse: 0.941595\n",
      "[800]\ttraining's rmse: 0.643628\tvalid_1's rmse: 0.939291\n",
      "[850]\ttraining's rmse: 0.636312\tvalid_1's rmse: 0.937723\n",
      "[900]\ttraining's rmse: 0.630007\tvalid_1's rmse: 0.935874\n",
      "[950]\ttraining's rmse: 0.623866\tvalid_1's rmse: 0.934433\n",
      "[1000]\ttraining's rmse: 0.618317\tvalid_1's rmse: 0.933516\n",
      "[1050]\ttraining's rmse: 0.612087\tvalid_1's rmse: 0.933385\n",
      "[1100]\ttraining's rmse: 0.607139\tvalid_1's rmse: 0.931804\n",
      "[1150]\ttraining's rmse: 0.601804\tvalid_1's rmse: 0.931249\n",
      "[1200]\ttraining's rmse: 0.596619\tvalid_1's rmse: 0.930541\n",
      "[1250]\ttraining's rmse: 0.592031\tvalid_1's rmse: 0.930211\n",
      "[1300]\ttraining's rmse: 0.588587\tvalid_1's rmse: 0.929852\n",
      "[1350]\ttraining's rmse: 0.584582\tvalid_1's rmse: 0.929582\n",
      "[1400]\ttraining's rmse: 0.580956\tvalid_1's rmse: 0.929853\n",
      "Early stopping, best iteration is:\n",
      "[1333]\ttraining's rmse: 0.586114\tvalid_1's rmse: 0.929223\n",
      "Training completed\n",
      "OOF Prediction completed.\n",
      "Shape of prediction (41697600,)\n",
      "Prediction completed\n",
      "CV OOF Score for fold 1 is 0.92922273656841\n",
      "fold 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's rmse: 1.16839\tvalid_1's rmse: 1.32043\n",
      "[100]\ttraining's rmse: 0.985335\tvalid_1's rmse: 1.19483\n",
      "[150]\ttraining's rmse: 0.89868\tvalid_1's rmse: 1.14604\n",
      "[200]\ttraining's rmse: 0.837092\tvalid_1's rmse: 1.11511\n",
      "[250]\ttraining's rmse: 0.797243\tvalid_1's rmse: 1.09898\n",
      "[300]\ttraining's rmse: 0.766515\tvalid_1's rmse: 1.08743\n",
      "[350]\ttraining's rmse: 0.744\tvalid_1's rmse: 1.07756\n"
     ]
    }
   ],
   "source": [
    "result_dict = make_prediction(train_X, train_Y, test_X, params=lgb_params, n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = result_dict.prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_37",
   "language": "python",
   "name": "py_37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
