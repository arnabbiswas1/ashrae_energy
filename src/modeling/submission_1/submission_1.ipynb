{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import feather\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATED_DATA_DIR = '/home/jupyter/kaggle/energy/data/read_only_feather/v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_dir):\n",
    "    train_df = feather.read_dataframe(f'{data_dir}/train_merged.feather')\n",
    "    test_df = feather.read_dataframe(f'{data_dir}/test_merged.feather')\n",
    "    print(f'Shape of train_df : {train_df.shape}')\n",
    "    print(f'Shape of test_df : {test_df.shape}')\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def create_date_features(df, feature_name):\n",
    "    '''\n",
    "    Create new features related to dates\n",
    "    \n",
    "    df : The complete dataframe\n",
    "    feature_name : Name of the feature of date type which needs to be decomposed.\n",
    "    '''\n",
    "    df.loc[:, 'year'] = df.loc[:, feature_name].dt.year.astype('uint32')\n",
    "    df.loc[:, 'month'] = df.loc[:, feature_name].dt.month.astype('uint32')\n",
    "    df.loc[:, 'quarter'] = df.loc[:, feature_name].dt.quarter.astype('uint32')\n",
    "    df.loc[:, 'weekofyear'] = df.loc[:, feature_name].dt.weekofyear.astype('uint32')\n",
    "    \n",
    "    df.loc[:, 'day'] = df.loc[:, feature_name].dt.day.astype('uint32')\n",
    "    df.loc[:, 'dayofweek'] = df.loc[:, feature_name].dt.dayofweek.astype('uint32')\n",
    "    df.loc[:, 'dayofyear'] = df.loc[:, feature_name].dt.dayofyear.astype('uint32')\n",
    "    df.loc[:, 'is_month_start'] = df.loc[:, feature_name].dt.is_month_start\n",
    "    df.loc[:, 'is_month_end'] = df.loc[:, feature_name].dt.is_month_end\n",
    "    df.loc[:, 'is_quarter_start']= df.loc[:, feature_name].dt.is_quarter_start\n",
    "    df.loc[:, 'is_quarter_end'] = df.loc[:, feature_name].dt.is_quarter_end\n",
    "    df.loc[:, 'is_year_start'] = df.loc[:, feature_name].dt.is_year_start\n",
    "    df.loc[:, 'is_year_end'] = df.loc[:, feature_name].dt.is_year_end\n",
    "    \n",
    "    df.loc[:, 'hour'] = df.loc[:, feature_name].dt.hour.astype('uint32')\n",
    "    df.loc[:, 'minute'] = df.loc[:, feature_name].dt.minute.astype('uint32')\n",
    "    df.loc[:, 'second'] = df.loc[:, feature_name].dt.second.astype('uint32')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/pyarrow/pandas_compat.py:752: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_df : (20216100, 16)\n",
      "Shape of test_df : (41697600, 16)\n",
      "Shape of train : (20216100, 16)\n",
      "Shape of train : (41697600, 16)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = read_data(CREATED_DATA_DIR)\n",
    "\n",
    "train_ordered_column_names = ['site_id', 'building_id', 'timestamp', 'meter',\n",
    "       'primary_use', 'square_feet', 'year_built', 'floor_count',\n",
    "       'air_temperature', 'cloud_coverage', 'dew_temperature',\n",
    "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
    "       'wind_speed', 'meter_reading']\n",
    "\n",
    "#Include row_id. All columns except meter_reading\n",
    "test_ordered_column_names = ['row_id', 'site_id', 'building_id', 'timestamp', 'meter',\n",
    "       'primary_use', 'square_feet', 'year_built', 'floor_count',\n",
    "       'air_temperature', 'cloud_coverage', 'dew_temperature',\n",
    "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
    "       'wind_speed']\n",
    "\n",
    "# Order the column names in convenient order\n",
    "train_df = train_df[train_ordered_column_names]\n",
    "test_df = test_df[test_ordered_column_names]\n",
    "print(f'Shape of train : {train_df.shape}')\n",
    "print(f'Shape of train : {test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort train and test based on time\n",
    "train_df.sort_values(['timestamp', 'site_id', 'building_id'], inplace=True)\n",
    "test_df.sort_values(['timestamp', 'site_id', 'building_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors = ['site_id', 'building_id', 'timestamp', 'meter', 'primary_use',\n",
    "#        'square_feet', 'year_built', 'floor_count', 'air_temperature',\n",
    "#        'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr',\n",
    "#        'sea_level_pressure', 'wind_direction', 'wind_speed']\n",
    "# target = 'meter_reading'\n",
    "\n",
    "# train_index = train_df.shape[0]\n",
    "# combined_df = pd.concat([train_df[predictors], test_df[predictors]], axis=0)\n",
    "\n",
    "# print(f'Shape of combined_df : {combined_df.shape}')\n",
    "\n",
    "# del combined_df\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do label encoding for the String type of feature\n",
    "feature_name = 'primary_use'\n",
    "lb = LabelEncoder()\n",
    "lb.fit(list(train_df[feature_name].values) + list(test_df[feature_name].values))\n",
    "train_df[feature_name] = lb.transform(list(train_df[feature_name].values))\n",
    "test_df[feature_name] = lb.transform(list(test_df[feature_name].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add date related features.\n",
    "train_df = create_date_features(train_df, 'timestamp')\n",
    "test_df = create_date_features(test_df, 'timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove time stamp and meter reading\n",
    "predictors = ['site_id', 'building_id', 'meter', 'primary_use',\n",
    "       'square_feet', 'year_built', 'floor_count', 'air_temperature',\n",
    "       'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr',\n",
    "       'sea_level_pressure', 'wind_direction', 'wind_speed',\n",
    "       'year', 'month', 'quarter', 'weekofyear', 'day', 'dayofweek',\n",
    "       'dayofyear', 'is_month_start', 'is_month_end', 'is_quarter_start',\n",
    "       'is_quarter_end', 'is_year_start', 'is_year_end', 'hour', 'minute',\n",
    "       'second']\n",
    "target =  'meter_reading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X : (20216100, 30)\n",
      "Shape of train_Y : (20216100,)\n",
      "Shape of test_X : (41697600, 30)\n"
     ]
    }
   ],
   "source": [
    "train_X = train_df[predictors]\n",
    "train_Y = train_df[target]\n",
    "test_X = test_df[predictors]\n",
    "\n",
    "print(f'Shape of train_X : {train_X.shape}')\n",
    "print(f'Shape of train_Y : {train_Y.shape}')\n",
    "print(f'Shape of test_X : {test_X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_X\t test_df\t train_X\t train_df\t \n"
     ]
    }
   ],
   "source": [
    "%who DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATED_DATA_DIR\t LabelEncoder\t create_date_features\t feather\t feature_name\t gc\t lb\t lgb\t np\t \n",
      "pd\t predictors\t read_data\t target\t test_X\t test_df\t test_ordered_column_names\t train_X\t train_Y\t \n",
      "train_df\t train_ordered_column_names\t \n"
     ]
    }
   ],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=100, n_jobs=16, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = lgb.LGBMRegressor(n_jobs=16)\n",
    "reg.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5715"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_X, train_Y, train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = reg.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  78.46021408,   78.46021408,   78.46021408,   78.46021408,\n",
       "        321.19454048,   78.46021408,   47.35351131,  321.19454048,\n",
       "       1914.56117302,  150.95286668])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df =  feather.read_dataframe(f'{CREATED_DATA_DIR}/submission.feather')\n",
    "\n",
    "submission_df.row_id = test_df.row_id\n",
    "\n",
    "submission_df.meter_reading = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78.460214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78.460214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>78.460214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.460214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>321.194540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  meter_reading\n",
       "0       0      78.460214\n",
       "1       1      78.460214\n",
       "2       2      78.460214\n",
       "3       3      78.460214\n",
       "4       4     321.194540"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.05G/1.05G [00:34<00:00, 32.5MB/s] \n",
      "Successfully submitted to ASHRAE - Great Energy Predictor III"
     ]
    }
   ],
   "source": [
    "! /home/jupyter/.local/bin/kaggle competitions submit -c ashrae-energy-prediction -f submission_1.csv -m \"1st baseline sub with just day features, LGB, No validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_37",
   "language": "python",
   "name": "py_37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
